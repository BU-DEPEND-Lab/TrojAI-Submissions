{
  "final_train_acc": 96.70443662594147,
  "final_train_loss": 0.02052182538500482,
  "final_combined_val_acc": 94.43925723670523,
  "final_combined_val_loss": 0.04835824893748467,
  "final_clean_val_acc": 94.43925723670523,
  "final_clean_val_loss": 0.04835824893748467,
  "final_clean_data_test_acc": 94.34305473219614,
  "final_clean_data_n_total": {
    "0": 224494,
    "11": 958,
    "12": 1398,
    "5": 4762,
    "6": 5796,
    "9": 2278,
    "1": 5588,
    "7": 1234,
    "8": 2277,
    "3": 5533,
    "4": 3798,
    "2": 1381,
    "10": 171
  },
  "final_optimizer_num_epochs_trained": [
    8
  ],
  "optimizer_0": {
    "device": "cuda",
    "epochs": 10,
    "batch_size": 8,
    "learning_rate": 5e-05,
    "optim": "adamw",
    "objective": "cross_entropy_loss",
    "objective_kwargs": {},
    "save_best_model": true,
    "early_stopping": "ES[5:0.01]",
    "soft_to_hard_fn": "torch.argmax(y_hat, dim=1)",
    "soft_to_hard_fn_kwargs": {},
    "lr_scheduler": "<class 'torch.optim.lr_scheduler.CyclicLR'>",
    "lr_scheduler_init_kwargs": {
      "base_lr": 1.25e-05,
      "max_lr": 0.0002,
      "step_size_up": 20142,
      "cycle_momentum": false
    },
    "clip_grad": false,
    "clip_type": "norm",
    "clip_val": 1.0,
    "clip_kwargs": {},
    "adv_training_eps": 0.0,
    "adv_training_iterations": 0,
    "adv_training_ratio": 0.0
  },
  "model_save_dir": "/wrk/tjb3/round7-final-final/id-00000916/model",
  "stats_save_dir": "/wrk/tjb3/round7-final-final/id-00000916/model",
  "experiment_path": "/wrk/tjb3/round7-final-final/id-00000916",
  "name": "NerLinear",
  "training_wall_time_sec": 32245.984776973724,
  "test_wall_time_sec": 1645.4532170295715
}